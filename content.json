{"posts":[{"title":"打扫房间与第零篇文章以及开心","text":"游戏还是很好玩的，不过要节制经过了几天的思考，其实是拖延，终于决定写下这篇文章了。 metroid prime 通关了，可惜没有第一时间写在当时在游戏中进入冰雪世界的感受，估计再也不会写了。好消息是，至少留下了这份记录。prime最后的boss战挺失望的，不是我想象的那种感觉。让鸟人族搞的仪式感那么强的大灾害只是一个大鱿鱼似的东西，真的是莫名其妙。而且，打完了也不会怎么样……我更喜欢超级银河战士的结局，生存恐惧的结局也很棒。对了，我看完了超银的全收集视频，这个游戏太超前了，在sfc时代营造出如此恐怖与寂静的感觉，好多细节。比如，再次和metroid宝宝相遇的那个场景，好多灰色的敌人一碰就碎，然后小蜜宝宝出现，把怪物吸收成粉末……再然后，只有一滴血的情况下，小蜜宝宝离开……如果当初我能在合适的时间相遇这部游戏该多好呢？不过，我已经和月下相遇了，在最合适的时间，真的也不能奢求太多。 读书比较顺利，运动与读书，继续加油最近恢复了运动与读书，看了spa相关的书籍。spa的开发也许更多是在实践中会有进步，如果只是理论，感觉不是太多。我看了测试驱动开发的书籍，有种恍然大悟的感觉。想起来接近10年前，我在学习mvc的时候，尝试所谓的测试驱动，可是失败了……那会儿如果我好好看看书，好好使用github也许我会更有收获也说不定。和老朋友交流的时候发现，我记了10年笔记，笔记软件各种更换，发现我没有利用起来这些记录……完全没有帮助，我没有再去看过，甚至自己也不想看。那么这些记录谁会看呢？我在这些记录上浪费的时间呢？当然有个好消息，我发现，我可以去看我曾经写下的博客，博客14年使用时间，最终文章寥寥可数，但是当我浏览的时候，确实找回了一些回忆，比如我学习symfony的记录。所以，我再次决定，从这篇开始换一个新的标题规则，所有文章用编号开始（这是为了便于后续文章的统计和管理），这边文章就是零了。 另外，我更换了新的域名，从长期的纠结中，我准备解放自己了。新的网址是https://oldyang.site，我发现我挺喜欢这个域名和名字的。这样就挺好。 最后，我要花一点点时间，至少把https://yangfs.blogspot.com上已经发表的文章迁移过来，作为一个新开始的纪念。可惜了那些最后没有发表的文章。 新的开始我和自己和解了，开始自由的做自己喜欢的和有价值的事情，用知识地图去规划未来的学习工作路径、做能让自己注意力集中的软件研究，写这个博客而不纠结于内容的错别字（我还是会定期修改的）。我有个观点，那些与众不同的时刻（可以称之为仪式感时刻）从事后看，大多平平无奇，而巨大的改变的时候在改变发生之时都是平常无比的。我希望未来回头看的时候，现在是一个绝大变化或者至少是个特别的时刻。","link":"/2023/04/22/0-clear-room-and-zero-and-happy-start/"},{"title":"建立一个全球可用的高速文件共享方案:开始就是曲折探索路径","text":"背景情况跨区域的团队协作存在的很多问题，想象一下，团队成员在伦敦、硅谷、西安、北京，团队中领域专家、有数据科学家等，提供IT工具协调大家共同开展一个项目存在很多挑战。我目前碰到的一个问题是，如何在这些团队成员间共享文件，核心需求是”快”，并且足够“简单”。作为简单来说，第一个能想到的就是FTP服务了，虽然古老，但是这个协议确实足够简单，然后就开始了我的折腾之旅。 FTP代理方案先考虑一个简单的情形，英国有个团队，北京有个团队，FTP服务器设置在北京团队的工作地点。这个情况下，北京的团队访问ftp速度是非常快的(8-10M/s),此时英国团队的访问速度就很慢了。当前阶段，现有团队喜欢了FileZilla做客户端下载文件。如何使得现有的使用习惯维持尽可能的不变提高速度呢？我想到了第一个方案就是FTP代理方案了。 FTP的代理不太多。第一个默认想到的就是反向代理方案，“对他使用Nginx吧”。但其代理缺点非常明显，就是配置特别复杂，因为FTP的passive模式，需要开放大量端口，这样公开报漏的服务器也不会安全[^1]。另外一个是使用专用的FTP代理软件，各种找只找到一个ftp.proxy[^2]。看了一下，12年没有更新了。当然，我还是花时间试了一下，结果失败了（纪念我的一个小时时间），并不是个很好使用的方案。 当然最重要的一点是，这样真的能提速吗？原来的模式是，英国团队直接访问北京的服务器，如果添加一个代理，比如代理放到香港，那么带宽如何处理？英国到香港再转到北京真的能速度快吗？这个时候我又思考了一下初衷，可能团队需要的就是一个“快”而“简”的文件共享服务。如果精力放到代理上是不是错过了关注点？ 一个新的独立的中间服务器建立一个中间FTP服务，地理位置上位于英国和中国中间，这样让两边都可以有适当的访问距离。这个时候我想到了点子是：掉换主服务器和备份服务器的位置。本来我的计划里，要用腾讯对象存储（COS）来备份所有的文件的，要不把方向调转过来，使用COS作为主服务器，然后利用本地每日进行备份，这样所有的团队都可以访问中间服务器，也许速度能平衡一下？说干就干～ 比较可惜，COS默认是不支持FTP服务的，官方提供了COSFTPserver工具[^3]。这里要吐槽一下腾讯云提供的这个工具，虽然不是不能用，实际配置过程中也确实有必要的提示，不过，使用腾讯自己的虚拟机依然配置困难（我碰到的问题是python依赖安装出问题，最终通过virtualenv模块顺利解决）。实际配置好之后，使用起来并不稳定，首先是挑选客户端，我常用的FE file explorer pro直接挂掉，以至于我一只以为没有配置好，最后发现FileZilla、cyberduck到是可以正常使用。缺点也是特别明显，就是速度慢，一些基本操作支持的并不好，比如，list速度比正常FTP慢很多，再比如，文件夹移动并不支持（勉强可以移动文件）。实现原理所限，估计也无法配置用户权限了。最后，也是最大的问题，速度的瓶颈在虚拟机器的带宽上。我之前没有想明白，就算用对象存储，实际流量也是先经过了架设FTP服务的虚拟机。比如，我使用轻量应用服务器的情况下，服务器只有1M带宽，然后此时的下载速度就只有可怜的200k/s。如果使用按量付费的服务器，带宽可以设置很高，此时北京的上传下载速度可以有1-2M/s，不过流量太贵了，1rmb/G，并且，如果按月选择高带宽的机器，价格更是贵的离谱，另外，可能还需要支付COS的费用。 最终这个方案暂时放弃了，价格贵，且很难保证稳定。我继续又想了，两个方案如果都不太行，是不是可以暂时放弃FTP的方案，关注于“高速文件共享”。 尝试围绕cloudFlare看看有没有合适的解决方案重新会到起点，我现在实际需要的是一个Building a Global High-Speed File Sharing System，这就让我想起了cloudflare，他的R2支持多地区部署，如果直接用R2是不是可以解决速度问题，并且，他的下载流量是不收费的，配合合适的工具[^4]，本地备份可以没有费用。cf试图解决的问题就是全球化部署应用，这种功能聚焦让我稍稍有点兴奋——爷我也要部署一个全球应用了。先找一些简单的项目试试，很可惜，cf的R2太新了，没有成型的适配项目（如果我有时间精力一定自己做一个……唉），我随手找到了flaredrive[^5]稍稍做尝试就配置成功了，作者自己也提供了在线试用[^6]。一开始我非常兴奋，但是稍加冷静发现了问题，过于简单了。比如，不支持重命名，不支持文件移动。我上传大文件的时候，没有任何进度提示，对用户过于不友好从而使这个项目不可用了。类似的我还找到了R2-Explorer[^7]，这次有了经验，看到TODO列表就知道不能用了,太简单了，甚至不能重命名文件夹。 简单的cf应用貌似走不通了，调研中我看到一个非常让我心动的商业软件R2FTP[^8]，如果把R2变成FTP会怎么样呢？是不是直接解决问题，可惜，这个网站貌似是个PPT产品，只有一个首页，github链接是空的，twitter上也没有人。不过，R2FTP到是给了我一个新的思路。还是围绕R2，能否有包装的比价好的外围工具呢？还真有！！sftpcloud[^9]貌似就是这样的工具，他提供服务端，然后数据存在R2里。尝试了，依然失败（哈哈，我都平静了，这是个围绕失败的故事）。问题原因不明，不过，大概成功了也不一定会有好的效果，因为毕竟数据中转还是在ftp服务所在的节点，当然也许还有继续尝试的价值，不过，这个方案只能暂时封存了。 幕间故事对于加速产品，也调研了一些商用产品，比如Ftrans[^10]、raysync[^11]，也尝试咨询了一下，不过这些方案都太有针对性了，基本都是关注于特定的领域（比如文件审核）。特别联系了一下ftrans的技术销售，具体实现方案需要在每个节点架设非常高性能的服务器，软件的授权价格也不是很美丽。 最终还是回到网盘方案对FTP方案进行了诸多尝试之后，最终，还是回到网盘方案，继续看看nextcloud吧。借助nextcloud我又重新熟悉了一下docker操作。其中部署也不是那么顺利，特别是我用的都是便宜虚拟机，部署还特别慢（我甚至在一台古老的台式机上部署了一个nextcloud）。部署过程中我发现了新的问题，nextcloud太重了，操作繁琐，真的是团队需要的工具吗？直观来看我的待办列表里一直有一项，“给nc配置s3后端”，总是无法完成。我就重新思考，nextcloud真的是我需要的吗？ 冷静下来，回到最开始的出发点，一个简单高速的文件分享服务。如果确定要用网盘实现，那么是不是还有其他的方案可以选择？于是，我不停的用关键词搜索其他的项目，然后得到了一串列表:seafile[^12],kodbox[^13],pydio[^14],filerun[^15]。seafile的简洁实用页面让我非常惊艳，真的是关注文件本身，而不是乱七八糟的其他东西（说的就是你，nextcloud）。kodbox可以找到serverless的部署教程，这也非常让我在意。在这个过程中，我不断的思考，“全球高速”，以至于要半夜从床上爬起来看CAP原理，想从最基础的角度考虑到我的解决方案，这是之前看过的一个重要博客出现在我脑海里————使用cloudflare部署全球高可用网站的方案[^16]。根据博客的思路，我完全可以把主机部署在就近的位置，用cloudflare的服务来就进回源，由于R2服务是最终一致的（也就是保证AP的），多节点主机也许也能获得不错的速度（至少保证能完成工作）。带着这个想法去看seafile的部署文件，发现了其中的问题：官方解答多节点部署必须相同域名，这个还不是主要问题，主要问题是官方的部署文件里使用memcache做小文件加速，必须每个节点同步，并且，官方不太保证这种部署方式，另外， 后端三个存储桶的保存要求，也让我意识到，目前这些网盘工具，关注点其实并不只是存储，重点在于meta信息（用户账户、文件评论、管理权限等）。 小节写了这么多，问题其实并没有被解决，不过，“我到底想要什么”这个问题在不断的失败、重新起步探索中被不停的聚焦了。比如，我越来越清楚，我需要的是个小而轻的工具。在多次部署cosftp的过程中，由于是用了COS存储，每次重新部署服务后，我之前的数据会突然出现在眼前，这让我意识到，我需要的是工具最好是和存储高度解耦的。一周的时间，每天1到数个小时，真的是让我重新找回了学习的感觉。 写下这段文字希望对后来人又帮助。 [^1]: 博客 Nginx反向代理FTP教程[^2]: 官网 ftp.proxy - FTP Proxy Server[^3]: 腾讯云文档中心 FTP Server 工具[^4]: 对象存储备份工具rclone Rclone syncs your files to cloud storage[^5]: flaredrive项目主页 github-flaredrive[^6]: flaredrive demo flaredrive demo试用[^7]: R2-Explorer项目主页 R2-Explorer[^8]: R2FTP主页 FTP Servers for Cloudflare R2 Storage[^9]: sftpcloud FTP &amp; SFTPas a service.[^10]: 飞驰云联高速ftp方案 Ftrans飞驰云联-飞驰传输[^11]: 镭速传输方案 镭速传输-专为企业提供大数据加速传输方案[^12]: seafile官网 Seafile开源的企业云盘[^13]: kodbox官网 kodcloud可道云[^14]: pydio官网 Pydio | Enterprise File Sharing &amp; Sync Platform[^15]: filerun官网 FileRun - Selfhosted File Sync and Share[^16]: 博客 分布式部署 cloudflared 让访客就近回源","link":"/2023/05/24/1-Building-a-Global-High-Speed-File-Sharing-System-Insights-and-Best-Practices/"},{"title":"FTP文件扫描脚本","text":"背景情况公司有个FTP，里面是一些共享文件：研发、行政等等都会往里面放东西。作为一个共享文件服务它足够简单，作为一个内网应用，也足够好用。用了很久了之后，现在要做一些改进，所以，希望知道目前一共有多少文件，这样也可以估算一下未来准备多少硬件。从安全角度考虑，我还没有拿到这个FTP系统的访问权限（拿到了我也不想贸然登录服务器，服务一切正常的时候尽量不要乱动）。统计文件的工作项目在我的“待办列表”里待了很久很久，终于在一个阳光明媚的上午，我准备把它处理好。 过程故事开始我把这个问题想简单了，我美滋滋的把这个任务丢给opencat(powered by gpt),结果，因为没有任何上下文的情况下，她给我回了一个shell脚本，用bash直接驱动lftp命令。 我隐约感觉不太对，直接的第一反应就是python。然后就开始了折腾，中间故事不表了，只说结果：我进坑了。ftplib是默认的库，运行效率特别低会卡死，考虑到有大量文件，默认的库可能确实性能不太好也可以理解（并不能……），我尝试更换了ftputil，结果中文支持不好。 最终回到了了bash+lftp的组合，值得庆幸的是，我很喜欢这个组合。并且也知道了，不要随便用python，ftp是那个年代的东西，就应该搭配同年代的工具 幕间休息 抓取数据和之前抓取数据不同，这次我并没有记录抓取进度，而是根据根目录下的文件夹，一个个抓取的。想起了上次抓取数据的经验，抓取过程肯定会断掉：所以断点重连和进度保存看似麻烦却实际上是必要的。这次让我惊喜的是，lftp自己有断点重连功能！！现在回头看看，不能太喜新厌旧。当然也有一些坑：比如文件名中可能有“空格”，这个被我考虑到了，但是问题出在存在“双空格”的情况，然后ls输出本来是多空格过滤为单空格:也就不能用awk了。改用用sed，然后发现macos的sed并不标准，准确的说，sed支持的正则表达式就不标准。文件名中的“&amp;”这些就更不用说了。再比如，日期字段并不规范，如果是去年及以前的文件，就会用年月日，而当年的文件就会显示具体时间。好在，这些小的细节gpt就可以帮忙了。 结果我拿到了所有的数据列表，截止6月5号的文件快照有了一份～可以作为后来分析扩容的基础了。更加开心的事情是，我的待办列表可以清除一项了。 最终代码123456789101112131415161718192021222324252627282930313233343536373839# this script (maybe) only working on mac# FTP server credentialsFTP_USERNAME=&quot;username&quot;FTP_PASSWORD=&quot;password&quot;FTP_SERVER=&quot;257.257.257.257&quot;#change this ^_^now=&quot;/firstdir&quot;OUTPUT=&quot;./output/now.txt&quot;#the functionfunction getFiles() { local path=&quot;$1&quot; if [[ ${path: -1} != &quot;/&quot; ]]; then path=&quot;${path}/&quot; fi local scriptpath=$(echo &quot;$path&quot; | sed 's/ /\\\\ /g' | sed 's/&amp;/\\\\&amp;/g') local output=$OUTPUT local remote_files local size line local filename local first lftp -u &quot;$FTP_USERNAME&quot;,&quot;$FTP_PASSWORD&quot; &quot;$FTP_SERVER&quot; &lt;&lt;EOF cd $scriptpath ls &gt; /tmp/files.txt # list all files and directories and save to a temporary file byeEOF while read line; do filename=$(echo &quot;$line&quot; | sed -n -r 's/^.*[Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec]{3} [0-9]{2}[[:space:]]+([0-9]{4}|[0-9]{2}:[0-9]{2}) (.*)$/\\2/p') echo $line &gt;&gt; &quot;${output}&quot; first=${line:0:1} if [[ $first == 'd' ]] ; then echo &quot;$path$filename&quot; getFiles &quot;$path$filename&quot; fi done &lt; /tmp/files.txt}getFiles &quot;$now&quot; 小结这个代码写完花了整整4个小时，一个上午的时间都在写，写的过程中想着还有其他的事情要处理。总之，并不是个很开心的工作，原因是心态问题，我一开始忘记了这个工作中肯定会出现各种“细节”需要不断调试，如果一开始就知道的话，心态能好很多。开心面对自己喜欢的工作应该是非常幸福的事情。","link":"/2023/06/05/2-find-how-many-files-on-ftp-server-with-script/"},{"title":"旅行游记","text":"去了大连。 感觉也是个很有意思的城市，长江路、天津街……这样的命名方式在青岛的时候也遇到过呢，作为2023年的行程，目前去过了大连、青岛、宁波。终于可以活动活动，感受中国的大好河山。 来到了十一假期，终于有空闲的时间可以思考了。想把博客的内容再更新一下，至少把旧博客都迁移过来，结果第一件事就是又又又更新了主题。这次更新希望能稳定一段时间。看看博客时间，高质量的输出依然很少，虽然最近做了不少东西，但是能静下心来写的依然很少。","link":"/2023/09/30/3-travel-of-dalian/"},{"title":"在ubuntu上部署一个php网站","text":"前言很久没有写教程了。其实日常写的东西并不少，但是我的博客还是断更了，距离上次写内容一个月以上了，这一个月的生活变化、人际关系变化特别多，总的来说：一切在客观上更加顺利了。写下这篇教程的时间，我有非常多的想法，但是要把想法落地落实，却又需要很多的时间和精力，本着尽量留下痕迹的方式，如果要写就尽量留下公开的痕迹吧，本着这样的思路写下这篇php网站的部署博客。 环境部署第一步是安装ubuntu，有一个可以部署应用的系统。由于本文撰写的时间，我选择了ubuntu 22.04(友人推荐的长期支持版)，至于ubuntu的安装这里不在赘述。 设置swap新的机器，最好设置一下swap防止内存不足，我的机器是2g，设置4g的交换空间应该就足够了。相关脚本如下： 12345678sudo swapon --show #查看是否设置了交换空间sudo fallocate -l 2G swapfile #创建交换文件# sudo dd if=/dev/zero of=/swapfile bs=1G count=2 #fallocate不可用时采用这个命令sudo chmod 600 swapfile #设置文件权限sudo mkswap swapfile #创建交换文件sudo swapon swapfile #启用交换文件echo &quot;/swapfile none swap sw 0 0&quot; | sudo tee -a /etc/fstab #添加内容到启动项中free -h #检查是否成功 我的系统是使用虚拟机安装的，一开始就被设置好了交换分区了。 安装docker第一步，肯定是安装docker，虽然整个网站是使用的php，不过，数据库最好还是容器化比较简单，安装docker按照教程来就可以。Install Docker Engine on Ubuntu,这是安装教程链接，使用过多次，每次都很顺利。 卸载旧版本：这个命令是卸载旧版本用的，如果没有安装旧版本，可以不用这个。 1for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done 设置docker的库,设置好docker软件库，为下载做准备 123456789101112sudo apt-get updatesudo apt-get install ca-certificates curl gnupgsudo install -m 0755 -d /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgsudo chmod a+r /etc/apt/keyrings/docker.gpg# Add the repository to Apt sources:echo \\ &quot;deb [arch=&quot;$(dpkg --print-architecture)&quot; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ &quot;$(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;)&quot; stable&quot; | \\ sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update 安装docker,并进行测试安装效果 123sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo docker run hello-world 安装openoffice最好给openoffice单独建立一个目录，这样使用compose可以直接部署openoffice服务。使用docker compose来部署openoffice服务 123456789101112version: &quot;3&quot;services: onlyoffice: container_name: oo7 image: onlyoffice/documentserver:7.4.1.1 ports: - &quot;9000:80&quot; restart: always environment: - JWT_SECRET=&lt;yourkey&gt; 当然可以使用命令解决以上问题：！！！注意，yourkey需要修改！！！ 1234567891011121314151617mkdir -p ~/workspace/onlyofficecat &lt;&lt;EOF | tee ~/workspace/onlyoffice/docker-compose.yamlversion: &quot;3&quot;services: onlyoffice: container_name: oo7 image: onlyoffice/documentserver:7.4.1.1 ports: - &quot;9000:80&quot; restart: always environment: - JWT_SECRET=&lt;yourkey&gt;EOFsudo docker compose up -d #下载镜像，启动服务 如果想停止服务，可以使用一下命令 sudo docker compose down http://localhost:9000,可以通过这个网址查看是不是部署成功了。 onlyoffice的镜像可能很大，可以把镜像提前准备好来节省实际部署时候的时间. 123sudo docker images #这个命令查看镜像，找到要导出镜像的idsudo docker save 0fdf2b4c26d3 &gt; oo7.tar #导出镜像文件，其中参数就是镜像idsudo docker load &lt; oo7.tar #导入镜像 这里还有一个细节：下载好的镜像，可以放在一个公开的服务器上（比如放到对象存储上），这样用wget下载速度就快了。例子：wget https://www.example.com/directlink/bj/webs/oo7.tar 这里的细节其实很多，因为虚拟机是NAT模式联网，我通过web界面把文件上传到了服务器上。这时候发现如果我当初安装的server版，没有gui，那么这个工作还非常难以实现呢。虽然就算有GUI，也是因为我有自己的文件中转服务才能简单实现。 部署php环境然后就是部署php环境的阶段，虽然按照正常流程是php、mysql、nginx这样依次安装，但是这样效率太低了，这里还是推荐用docker安装。使用docker-lnmp项目来进行php网站的配置，部署和后续迁移都会方便。 如果以dzzoffice项目的安装为例子，把源代码放到默认的www目录中，目录结构如下：|____docker-lnmp| |____nginx| |____php74| |____php81| |____php73| |____php72| |____php71| |____mysql| |____php80| |____php56| |____redis|____www| |____static| |____misc| |____install| |____user| |____config| |____dzz| |____core| |____data| |____admin 123456789101112131415161718192021222324252627282930313233343536373839find . -name &quot;._*&quot; -print ## 检查缓存文件find . -name &quot;._*&quot; -delete ## 清除缓存find ./ -mindepth 1 -maxdepth 2 -type d | sed -e 's;[^/]*/;|____;g;s;____|; |;g' 确认目录结构，如上图cd docker-lnmp #来到环境目录cp .env.example .env #创建配置文件sed -i 's/NGINX_HOST_HTTP_PORT=.*/NGINX_HOST_HTTP_PORT=8086/' .env #替换其中的某些配置，比如，设置端口docker network create backend --subnet=172.19.0.0/16 #关键步骤，为容器应用创建子网络docker network ls | grep backenddocker compose up -d nginx php74 mysql #启动应用，这个命令会非常慢，可以尝试配置docker源的方式加速# echo '{&quot;registry-mirrors&quot;:[&quot;http://hub-mirror.c.163.com&quot;]}' | sudo tee /etc/docker/daemon.json# systemctl restart docker# docker info #查看配置结果# #在Dockerfile中的apt也可以配置更新源来加速，在apt-get update之前添加一行命令就可以了# RUN sed -i s@/deb.debian.org/@/mirrors.aliyun.com/@g /etc/apt/sources.list# #sed格式如下# sed '/^RUN apt-get update/ i\\# RUN sed -i s@/deb.debian.org/@/mirrors.aliyun.com/@g /etc/apt/sources.list# ' Dockerfiledocker compose restart nginx #修改配置后启动某些容器sudo sh -c &quot;cat &lt;&lt;'EOT' &gt; ./docker-lnmp/nginx/conf.d/default.confserver { listen 80; server_name localhost 127.0.0.1; root /var/www; index index.php index.html; charset utf-8; default_type text/html; location / { try_files \\$uri \\$uri/ /index.php\\$is_args\\$args; } include conf.d/fpm/php74-fpm;}EOT&quot; #设置 上面的脚本细节特别坑，sh和cat会对 $ 解释两次，所以要用两次防止过滤的方式。 然后安装php网站会碰到以下错误：Host '172.19.0.74' is not allowed to connect to this MySQL server参照这个解决思路可以通过更改访问权限来解决问题。 进入容器：docker compose exec mysql mysql -u root -p,执行命令： 12345show databases;use mysql;select host,user from user; --查看用户权限配置update user set host = '%' where user ='root'; --开放外部连接flush privileges; --更新权限 然后就可以安装任意的php网站了，为了在网速“不快”的服务器上，可以利用docker save -o myimages.tar image1:tag1 image2:tag2 把多个镜像导出到一个文件，这样就可以整体搬家了。 bonus 配置部署包网站在后期开发中可能需要添加扩展，扩展要通过composer安装。这样的情况目标机器上还是需要安装php，不同的系统不一样。rocky9.3参考这里。 12345678sudo dnf config-manager --set-enabled crbsudo dnf install \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm \\ https://dl.fedoraproject.org/pub/epel/epel-next-release-latest-9.noarch.rpmsudo dnf install dnf-utils http://rpms.remirepo.net/enterprise/remi-release-9.rpm -y #key cmd linednf module list phpsudo dnf module enable php:remi-7.4 -y 当然还有个apt的例子。 12345sudo apt-get updatesudo apt -y install software-properties-commonsudo add-apt-repository ppa:ondrej/phpsudo apt-get updatesudo apt -y install php7.4 然后就是安装composer了,为了部署方便，安装在本地就可以。 12345php -r &quot;copy('https://getcomposer.org/installer', 'composer-setup.php');&quot;php -r &quot;if (hash_file('sha384', 'composer-setup.php') === 'e21205b207c3ff031906575712edab6f13eb0b361f2085f1f1237b7126d785e826a450292b6cfd1d64d92e6563bbde02') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;&quot;php composer-setup.php \\php -r &quot;unlink('composer-setup.php');&quot; \\php composer.phar require casdoor/casdoor-php-sdk #安装sdk的例子 新的问题配置到这里，虽然一切看似正常了，不过curl可以正常访问casdoor，可是php却提示缺少证书。这个时候才发现，证书是被配置在docker里的！因此，证书要暴露给docker……真的是复杂啊。 进入docker，参考这个文档可以临时更新证书。 12sudo docker exec -it &lt;container_id_or_name&gt; bash## update certificates 特别注意如果修改了.env一定要重新rebuild，env的参数进入dockerfile是build时发生的。 12docker compose downdocker compose up -d --build mysql nginx php74 新的问题mysql可能会出现“Restarting (1) Less than a second ago”不断重启，这时可以用logs命令查看问题所在。 sudo docker logs container_id 具体例子dzzoffice部署通过以上部署，dzzoffice网站就可以安装了,http://ip:port/install/index.php这个网址是固定安装目录。 网站运行起来了，然后就是设置，第一项是把onlyoffice配置好，在线浏览文章的功能是必要的。 然后一个可以共享文件的小平台就建立好了。 Troubleshooting使用文中的docker脚本，有时候再第一次配置错误的情况下，会产生“奇怪的跳转”，比如，访问http://127.0.0.1:8086会强制跳转到http://127.0.0.1，经过多次测试，发现这是“客户端”的某种“记忆”。解决方式也很简单，对于safari浏览器，可以把对应域名的缓存删除掉。对于Edge、chrome等浏览器，使用开发者模式，在”网络选项卡“上把”禁用缓存“勾选上，然后再访问一次这个网页就能把缓存遗忘了。 鸣谢特别鸣谢我的妻子，她帮我写了一个小的手册文章，所以我有时间精力写下这篇教程。","link":"/2023/11/09/4-how-to-setup-up-a-php-website-with-mysql-on-a-new-ubuntu/"},{"title":"部署一个支持小组开展工作的jupyter环境","text":"前言python统一环境从来都是一个复杂的问题，特别是要多人合作的时候（甚至两个人合作要统一环境也经常出问题）。环境配置不一致很容易打击团队的积极性，让本来应该聚焦到具体问题解决上的注意力被分散。晚上有很多教程，都是只是讲某个技术细节的配置，很少有完整的方案。本教程详细介绍一下如何配置一个帮助管理员或者小组领导带领小队完成数据分析任务的jupyterhub环境，包括环境安装、用户配置等诸多细节。 内网穿透是的，从内网穿透开始讲，太多的教程都会忽略服务最终如何访问到的问题，好像所有人都有了很好的网络环境，实际上的情况往往很复杂，很多新手可能就被“卡”在这里。当然，本教程也忽略了操作系统的安装这个步骤，尽量做到取舍有度。 假设你已经有了一台可以上网的ubuntu主机，本教程是基于一台NAT模式的虚拟Ubuntu进行的。登录tailscale的官网，找到对应的安装命令。 curl -fsSL https://tailscale.com/install.sh | sh相关的详细教程可以在官网查到https://tailscale.com/download/linux,官网贴心的附带了分步骤安装教程。 其实只是需要下载一个25MB的包，因为网络的原因，这个步骤我失败了很多次。原因是tailscale的服务器在境外。如果能有一个安装了科学透明代理的网络环境，这类服务安装起来会简单很多，等后续的教程中我在补这部分吧。 启动的命令是： tailscale up 这里有个小提示：命令行给出的地址，并不需要一定要“本机”登录，实际上我用我的笔记本电脑访问了图上的地址，完成了验证。 下一步我在macbook上安装tailscale终端，就可以进入虚拟的内网，访问服务器了。跨区原因不能在应用商店安装，用brew安装也很方便。 123456brew install tailscale #安装tailscalesudo tailscaled install-system-daemon #启动为系统服务#sudo tailscaled uninstall-system-daemon #这个命令应该是注销系统服务tailscale uptailscale ip #查看ip地址tailscale status #查看设备情况 启动服务就可以把终端和服务器放在一个内网里了，这样可以随时访问到NAT中的虚拟服务器了。我的教程这里相当于一个例子，如果你使用的是不同设备，官网有详细的教程，链接在这里安装终端的链接 本教程重点在于全面细节，为了能够随时访问到该机器，自然还要在机器上安装sshd服务，命令如下： 12sudo apt install sshsudo systemctl ssh 然后，使用你自己习惯的ssh终端，通过tailscale服务的内网地址，就可以访问到服务器了。这里有个个人碰到的小提示：我在tailscale使用中，有时明明服务在线，但是却访问不到主机，此时我发现使用ipv6就可以轻松访问到主机了。 安装conda第一时间找到官方教程总是不会错的Miniconda，根据教程可以完成安装。 官方的教程如下： 1234mkdir -p ~/miniconda3wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.shbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3rm -rf ~/miniconda3/miniconda.sh 以下教程均是按照官方脚本执行之后配置。不过，这里强烈建议不要完全按照官方教程来做，原因见后面章节。如果你能把教程全部看完之后再操作，建议把minicoda安装在/opt/miniconda/。 安装好之后，记得运行~/miniconda3/bin/conda init bash这个命令把miniconda加入到环境变量里,然后重新登录一下就激活了conda的base环境了。 安装jupyterhub虽然也有非常方便的tljh安装方式。实际落地的话，下载tljh特别考验网络速度，完全没有conda来的快捷，另外使用conda安装更好定制，所以，这里推荐用conda来安装jupyterhub。 123456789101112conda create -n python310 python=3.10 #创建基础环境conda create -n jupyterhub --clone python310 #根据基础环境创建jupyterhub环境#这里提供一些可能会用到的管理命令#conda env remove --name jupyterhub #适当的时候可以删除环境#conda env list #现实当前的环境列表conda activate jupyterhub #激活环境#conda search -c conda-forge nodejs --info #找到允许的版本列表conda install nodejs #安装nodenpm install -g configurable-http-proxy #这个可以安装代理服务python3 -m pip install jupyterhub jupyter notebook #这个可以顺利安装notebook#如果网速过于慢，可以试试国内的源#pip install jupyterhub jupyter notebook -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com 经过上面的操作，jupyterhub已经装好了，可以尝试启动jupyterhub了。 1234mkdir ~/jupyterhub #创建用来放置jupyterhub的目录cd ~/jupyterhub/jupyterhub --generate-config #会生成配置文件模版jupyterhub -f jupyterhub_config.py #运行jupyterhub,这个命令一般也用来测试jupyterhub文件 如果一切正常访问http://ip:8000这个地址就可以看到jupyterhub界面了，然后就是把jupyterhub配置的可用。这里特别提示一下，jupyterhub默认使用的是linux系统本身的用户账户系统，用户名和口令就是linux系统本身的用户名和口令，新建用户也是同理。 配置jupyterhub配置jupyterhub也是很重要的一环，基本而言就是围绕配置文件进行；不过在那之前可以考虑先把内核配置好。 12345pip3 install ipykernelpython3 -m ipykernel install --name=jupyterhub --display-name &quot;dev_default&quot;#jupyter kernelspec list #列出kernel#jupyter kernelspec uninstall jupyterhub #卸载kernelpip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas # 安装一个包看看虚拟环境中的包是否在kernel中生效 两个心得： 因为使用jupyterhub环境安装的jupyterhub（怎么读着那么绕……），所有jupyterhub再后来的子用户就默认都具有jupyterhub这个虚拟环境，安装kernel至少在这里并不是必须的（更绕了），但这里还是提一下，如果想给所有用户都配置可选的kernel意外的困难，毕竟jupyterhub就装在jupyterhub虚拟环境下（……）； pip -i参数可以加快安装速度，另外也不用额外的更改源，意外的好用。 12345``` pythonc.JupyterHub.admin_users = {'peter'}c.Spawner.default_url = 'tree'c.LocalAuthenticator.create_system_users = True 以上命令分别是设置默认界面、设置管理员、设置添加用户方式等等，这个方面可以参考文档，当然直接阅读jupyterhub --generate-config命令生成的模版学习如何配置也是非常棒的。学习的重点就是更改一些配置，然后用命令直接运行看看结果。很多问题是在使用中发现的，比如现在jupyterhub添加用户是会报错的。 这个报错是我意料中的，原因自然是权限不足，目前普通账户无法创建用户。（意料中出错，然后修正，有点测试驱动的意味在里面呢）。为了解决以上问题，同时也是为了方便日常管理jupyterhub服务，把这个注册为系统服务。 12345678910111213141516171819202122232425which jupyterhub #这个命令确定Environment的目录#这段脚本根据你自己的情况改一下再用sudo sh -c &quot;cat &lt;&lt;EOT &gt; /etc/systemd/system/jupyterhub.service[Unit]Description=JupyterHub[Service]User=rootEnvironment=PATH=/home/peter/miniconda3/envs/jupyterhub/bin/:/usr/local/bin/:/usr/bin/:/usr/sbin/ExecStart=/home/peter/miniconda3/envs/jupyterhub/bin/jupyterhub -f /home/peter/jupyterhub/jupyterhub_config.py[Install]WantedBy=multi-user.targetEOT&quot;#以上命令是以root用户安装conda为例子进行的sudo systemctl daemon-reloadsudo systemctl start jupyterhubsudo systemctl enable jupyterhubsudo systemctl status jupyterhub#sudo systemctl restart jupyterhub#sudo systemctl disable jupyterhub#sudo systemctl stop jupyterhub#sudo journalctl -u jupyterhub -n 50 #这是查看日志的命令 这样整个jupyterhub就配置好了。再次尝试添加用户，成功添加。然后用管理员登录，给这个用户设置一个密码sudo useradd -m -s /bin/bash hubuser &amp;&amp; sudo passwd hubuser，用户就可以登录了，然后我们就看到了错误。 这是说明一开始就配置错误了，conda被安装在了用户目录下，新添加的用户完全访问不到。等于是官方教程的mkdir -p ~/miniconda3这个命令开始就出错了，应该把miniconda安装在/opt里才比较合适，事到如今，只能尝试修复一下权限了。 12sudo -u hubuser /home/peter/miniconda3/envs/jupyterhub/bin/jupyterhub-singleuser -hchmod 755 ~/home/peter/ 提示：如果有机会重新配置conda，一定要安装在/opt目录。 虽然配置工作很辛苦，不过至少环境可以统一了，如果用户多一点（也不需要特别多，节约的精力依然可观），使用conda在对应虚拟环境下安装的包都可以让所有用户共享。对于某些的特定的共享文件，可以放在共享系统库目录中共享,python -c &quot;import sys;print(sys.path)&quot;命令输出的地址都可以放置共享文件。另外对于，需要使用ctypes.cdll.LoadLibrary函数加载的模块，系统会寻找LD_LIBRARY_PATH设置的目录，对于systemd，设置两个节点就可以了。 1234#这是配置例子，实际测试过并没有成功[Service]Environment=&quot;PATH=/usr/local/bin:/usr/bin:/bin&quot;Environment=&quot;LD_LIBRARY_PATH=/opt/gams/&quot; 需要在jupyterhub_config.py文件中配置保留哪些环境变量参考链接。 1c.Spawner.env_keep = ['LD_LIBRARY_PATH','PATH', 'PYTHONPATH', 'CONDA_ROOT', 'CONDA_DEFAULT_ENV', 'VIRTUAL_ENV', 'LANG', 'LC_ALL', 'JUPYTERHUB_SINGLEUSER_APP'] 我们来捋一下环境变量的传递：首先系统运行bash的时候会加载用户自己和系统通用的环境变量-&gt;conda环境会激活部分环境变量-&gt;systemd的unit文件忽略系统变量，可以自己设置-&gt;jupyterhub要设置过滤哪些，默认继承的环境变量里没有LD_LIBRARY_PATH。感觉就是个环境变量的传递游戏。 用户目录配置sudo mkdir share &amp;&amp; chmod 777 share/首先建立一个目录供所有人共享使用。 建立起基本的目录结构mkdir pub codes project 通过以下方式可讲目录的权限给到任意用户。 123456cd /var/share/project/mkdir 01-notebookssudo suchmod 777 01-notebookscd /home/hubuser/ln -s /var/share/project/01-notebooks 01-notebooks 通过以上设置，就可以使用linux的权限管理机制来管理用户的文件了。 gams安装这是安装文档 这个可以用来参考在虚拟环境中安装gams 安装gams其实比想的要简单，只要按照文档把gams解压，并配置好环境变量就可以了。 对于jupyterhub的情况，在systemd的注册脚本中，在Environment配置节点，把gams所在的目录添加进去，就可以完成配置了。本教程主打一个详细，看到无数教程都写如何配置，但是最重要的其实是怎么确定配置好了。这里提供gams的例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950sh -c &quot;cat &lt;&lt;EOT &gt; ~/example.gamsSets i canning plants / seattle, san-diego / j markets / new-york, chicago, topeka / ;Parameters a(i) capacity of plant i in cases / seattle 350 san-diego 600 / b(j) demand at market j in cases / new-york 325 chicago 300 topeka 275 / ;Table d(i,j) distance in thousands of miles new-york chicago topeka seattle 2.5 1.7 1.8 san-diego 2.5 1.8 1.4 ;Scalar f freight in dollars per case per thousand miles /90/ ;Parameter c(i,j) transport cost in thousands of dollars per case ; c(i,j) = f * d(i,j) / 1000 ;Variables x(i,j) shipment quantities in cases z total transportation costs in thousands of dollars ;Positive Variable x ;Equations cost define objective function supply(i) observe supply limit at plant i demand(j) satisfy demand at market j ;cost .. z =e= sum((i,j), c(i,j)*x(i,j)) ;supply(i) .. sum(j, x(i,j)) =l= a(i) ;demand(j) .. sum(i, x(i,j)) =g= b(j) ;Model transport /all/ ;Solve transport using lp minimizing z ;Display x.l, x.m ;EOT&quot; 以上是官方例子的模型，在用python调用。 1234567from gams import GamsWorkspaceimport osws = GamsWorkspace()job = ws.add_job_from_file(os.getcwd() + &quot;/example.gams&quot;)job.run()for rec in job.out_db[&quot;x&quot;]: print(f&quot;x({rec.key(0)},{rec.key(1)}): level={rec.level} marginal={rec.marginal}&quot;) 小结至此，一个小型的可多人共享的jupyterhub配置好了，团队需要共享的代码可以放到share目录中，权限根据linux系统的权限来管理。对于管理员来说，需要进行的操作无非就是如下几种： 创建用户，并设置密码以及忘记密码时重置密码 维护项目目录的文件内容 把目录挂载给指定用户，并设置适当的权限 删除用户的权限或者不允许其再看到对应的目录 给虚拟环境安装适当的软件包 以上就是管理员所有操作的枚举，只要管理员熟悉了以上操作，就可以让团队利用好jupyterhub顺利推进工作啦。","link":"/2023/11/10/5-jupyterhub-for-team-work/"},{"title":"随着假期开始的充电","text":"前言假期屯了不少书，准备给自己一个充实的假期。好多东西想学习，airflow、superset、scrapy等，另外还想学习rocky linux，还有之前的kvm和pve的内容也想巩固。总之就是要搞个homelab出来～ 另外，我终于有机会把这个学期学的内容进行实践了，目前的规划是给旧笔记本安装fedora，给小mini主机安装pve。新的小mini主机就作为服务器使用了。 fedora的安装还是很简单的，调整一下AHCI就能找到硬盘了。可是即使如此我也安装了两遍。问题出在密码上，新安装之后密码无法进入，第二次安装的时候注意到了原来是输入密码的时候输入法是大写状态。DELL电脑的win系统开机就会风扇狂转，现在安装了fedora之后，变得特别安静（下载软件的时候还是会有一点点声音）。 然后就是重新搭建基础家里的旧电脑有点多了，显示器只有一台（多了桌子也放不了），要让我的mac重新能支持双屏幕估计要等到下次升级了。经过多次思考后决定让mini主机安装PVE：第一点，如果我用fedora服务器，每次还要安装sshd和vnc，考虑到这麻烦情况，还不如直接用http控制电脑；第二点，考虑到要做的本地项目组件众多已经有点复杂了，越早熟悉虚拟化平台能够越早启动项目。第三点，如果可以把远程开发环境搞好，以后就有了坚实的homelab基础了。 安装PVE长时间的调研准备，开始工作居然拖了这么久。这里要说一下，全新的mini主机自带win11 pro，什么都还没有安装开机风扇就想个不停，虽然我现在不能明确问题所在，不过，这个情况让我对win依然是不太有好感。 先不要考虑ip地址的设置，一把点安装。PVE安装时间意外漫长，检查了一下，居然卡在了“create LVs 3%”，没有想到一开始就这么不顺利。也有提示说不用管它，这是正常现象，果然多等了一会儿，后面安装就非常快了。安装成功了，然后就是要考虑ip地址接入的问题了，找根网线把机器接入到网络中，修改interface文件和hosts文件，把ip地址设置到静态。 1234vi /etc/network/interfacesvi /etc/hostssystemctl restart networkingreboot 安装操作系统的时候意外顺利。 一天下午的时间，我就安装了pve,fedora,rocky linux，感觉是挺充实的，并且由于之前阅读的关系，kvm的书籍让我重新理解了网络的模型，可以在配置上更加得心应手。 1234sudo dnf install qemu-guest-agentsudo systemctl start qemu-guest-agentsudo systemctl enable qemu-guest-agentsudo systemctl status qemu-guest-agent 创建好base镜像，系统配置乱了随时回来。 修正系统时间既然要折腾，就肯定有小修小补，比如，发现时间错误了，要改一下时间。pve的时间是错误的，而虚拟机的时间是正确的（date -R）。先尝试用hwclock解决了，一个有意思的现象，根据命令行修改时间之后，我的登录直接退出了！应该是系统根据这个时间判断登录时间的，非常透明和“干净”的感觉!查了一些文档，果然如果条件允许的话还是试试ntp服务吧。 安装fedora服务器把dell xps改装成了小型服务器，合上盖子不休眠真的很容易配置。 1234sudo vi /etc/systemd/logind.conf change #HandleLidSwitch=suspend to HandleLidSwitch=ignoresudo systemctl restart systemd-logind.service 然后就是配置虚拟机和插件： 123dnf install cockpit-navigator cockpit-machinesdnf install qemu-kvm libvirt libvirt-daemon virt-install virt-manager libvirt-dbussudo dnf install podman 一个小型的服务器也准备好了，至此我的书架上有了linux、macos、win三个小型的环境，另外还有个pve主机可以一步一步继续学习了。 安装airflow开始安装体验，官方的文档有很详细的安装教程，不过我还是想先从podman开始。 123456789dnf install podmanpodman pull apache/airflowpodman run -d -p 8080:8080 airflow#安装并启用端口sudo firewall-cmd --list-allsudo firewall-cmd --zone=public --list-portssudo firewall-cmd --zone=public --add-port=8080/tcp --permanentsudo firewall-cmd --reloadsudo firewall-cmd --zone=public --list-ports 并没有成功，podman ps发现容器退出了，使用podman logs -l返回的内容居然是“airflow command error”，不得不说，非常诡异。最后尝试使用helloworld测试一下podman是否装好。 12podman run hello-worldpodman logs -l 看到输出的一瞬间我明白了。airflow的错误输出正是由于logs命令运行正常，是我没有对airflow做正确的配置。这个错误虽然很小，但是也非常有趣，容器内部和外部环境形成了“隔层”，但是内部程序是不知道的，他努力的发出声音也是因为没有配置好，但是这个声音的渠道被我听到了，是不是就构成了一种“穿透”。形式上就是，我输出podman日志的预期看到了容器的日志，从而担心整个podman环境出现了什么问题。我觉得这也是奎因第二类问题的一种体现。 如果用容器运行airflow不是最默认的方式肯定是有原因的，尝试没有配置好的话，就按照最默认的方式来吧。 干净的系统居然没有pip，需要自己安装python -m ensurepip --default-pip。 基础硬件设施解决之后发现，其实很多开源软件直接安装即可，容器化并不能让每个问题都简单，甚至有时在不熟悉的情况下会复杂化。 安装superset这次学老实了，先跟着教程走。superset感觉是个“纯”的python包，如果考虑后续使用，也许可以借鉴一下jupyterhub的安装经验。 配置防火墙启动：superset run -h 0.0.0.0 -p 8088 --with-threads --reload --debugger 启动之后发现无法登录，依然是仔细看日志，然后在社区找到处理方案,这里提一下，这个社区的处理方案，提问人提问的方式太棒了非常详细。最终采用了两个配置建议（包括“TALISMAN_ENABLED”），最终见到了欢迎页面。中间一度很多错误，让我转向了docker部署，不过最终还是解决了。（原因是忘记运行superset init命令了） 123456789[Unit]Description=Superset Application[Service]User=peterExecStart=/usr/bin/bash /home/peter/superset/superset_run.sh[Install]WantedBy=multi-user.target 1234source /home/peter/venv/bin/activateexport FLASK_APP=supersetexport SUPERSET_CONFIG_PATH=/home/peter/superset/superset_config.pysuperset run -h 0.0.0.0 -p 8088 --with-threads --reload --debugger 最后就注册成服务，可以随意使用了。其中有个点，如果User配置为root，账号密码不可用。这样让人非常在意账号密码存在哪里？还是说执行初始化的时候和用户关联了？ 配置casdoor嗯，突然配置这个东西，确实有些跳跃。不过类似于游戏技能树一样，这个模块配置好可以很大程度上解决登录问题。首先，还是看看rocky上怎么安装docker吧，毕竟，podman还是有些问题，生产环境中docker用的更多一点。经过测试，casdoor确实可以在内网部署https服务，使用acme.sh申请证书。 12sudo docker compose restart casdoorsudo docker compose restart casdoor_proxy 配置这个重点是要生成证书，这样要学习一下acme.sh了。curl https://get.acme.sh | sh -s email=fsy@gmail.comacme.sh结合cloudflare可以很容易的生成证书。主要都是证书的安装细节和注册脚本了。根据需要要安装cron:sudo dnf install crontabs 无论如何，安装sso的服务端都还是简单的，下一步就是考虑如何把用户端配置好，配置流程如下： SSO_CLIENT_ID和SSO_CLIENT_SERCRET是在SSO服务端生成的； 应用的实际生成地址需要提供给SSO作为callback; 使用命令行注入ca.cer的位置；export NODE_EXTRA_CA_CERTS=/real/path/ca.cer; 把sso中应用公钥的信息提供给应用。 注册到这里就出错了，node无法识别le的证书，本来node就没有le的证书，这里更换zerossl证书试试（之后依然要重新注入）。最后还是选择了注册zerossl的账号，至此，我终于了解了证书的运作机制，并了解了acme.sh工具的使用。可以参考的教程还是很多的. 经过一通操作，至少在自己的实验环境搞定了。然后把app和sso都准备一份部署工具，等完全部署好，就可以了。 其中使用一个fetch函数可以验证证书有没有配置好。 12345fetch('https://door.tcub.site') .then(response =&gt; response.text()) .then(data =&gt; console.log(data)) .catch(error =&gt; console.error(error));//node test.js node当然需要专门安装: 12dnf module list nodejsdnf module -y install nodejs:20/common 以casdoor为中心，就能很大程度上解决用户管理的问题了。 troubleshoot早起发现无法正常生成域名的证书，“明明昨天还是正常的呀”然后一看昨天的证书其实也是不正常的。却少必要的公共证书。经过一个小时的波折，冷静了下来，法相原来是dns_cf的key的问题。之前的key只是访问一个域名的（或者至少zone_id只能指向一个域名）。zone_id可以在dns管理对应域名的信息页面找到。令牌的话，在个人信息（右上角）里：My Profile-&gt;API Tokens-&gt;use DNS:edit_template就可以获得了。 开始配置homelab假期开始，终于有足够的时间配置属于我的homelab了，服务器也就位了。借助pve和cloudflare尝试构建homelab。之前我一直担心，cf的tunnel是不是不够快？现在想到我的homelab我突然明白了，如果我自己用就没有这个问题了。首先试试authentik 首先，尝试用podman部署一下authentik。sudo dnf install podman安装podman。然后就是一系列命令： 12345sudo dnf install python3sudo dnf install python3-pippip3 install podman-composesudo dnf install -y epel-releasesudo dnf install -y pwgen 使用podman失败了，但是不清楚可能的原因，所以，还是老老实实装docker吧。 1234567sudo dnf remove docker docker-client docker-client-latest docker-common docker-latest \\ docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-enginesudo dnf -y install dnf-plugins-coresudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.reposudo dnf install docker-ce docker-ce-cli containerd.io docker-compose-pluginsudo systemctl start dockersudo systemctl enable docker.service 根据教程进行安装到是很快，利用cf的tunnel也很容易把服务发布出去，不过证书和配置应用搞不好就没有那么简单了。毕竟这个compose文件都没有看太懂。自己的小homelab运行一两天就会发现进程号到了几十、几百万，估计还是哪里有泄漏。果然很多事情是自己实践之后才能发现的。 有了自己的homelab之后发现vscode更加好用了，然后再次意识到，还是使用证书访问更加方便。 123ssh-keygen -t rsa -b 4096ssh-copy-id -i ~/.ssh/id_rsa.pub user@192.168.1.1 //for linux clienttype $env:USERPROFILE\\.ssh\\id_rsa.pub | ssh user@192.168.1.1 &quot;mkdir .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys&quot; // for win node网站镜像化一个简单的node网站，是用的时候确实有问题的情况，直接发布镜像会方便一些。建立数据库可能会用到的一些脚本。 1npx prisma db push","link":"/2024/01/13/6-setup-homelab/"},{"title":"typescript的类型在运行时就没有了","text":"最近开发碰到一点点坑typescript在运行时的类型已经不存在了。所以，虽然我在request.params中可以很好的推断获得number，但是当在prisma的where中进行调用的时候还是会出现类型错误。这个坑浪费了我1个小时。","link":"/2022/10/13/about-ts-type-not-in-runtime/"},{"title":"开始了我的kaggle学习","text":"学习的背景感谢我的妻子来到我的生活，她真的是非常有智慧的女性，我感觉治愈了有点点在低谷的我。在她的鼓励下，我重新开始看kaggle，居然顺利学完了所有的入门课程，现在开始关注一些比赛。我的工作推进虽然缓慢，不过我内心平静了很多，感觉可以慢慢推进做一些事情了，虽然现在，偶尔还是很困并且容易劳累，也许我该健身一下。又是个碎碎念的博客呢。生活的中的细节多了，我目前也能静下来了，和形而上学和解了，未来也许可以写出来不错的文章。放张图记录一下最近的生活吧～ 相关信息原文地址：开始了我的kaggle学习","link":"/2022/04/15/arc-0-start-my-kaggle/"},{"title":"如果更早遇见是不是会好一点呢？","text":"读完了《推理竞技场》。 跟自己说着很久没有看书了，然后抽了两个半午休看完了这本书。我自己对这本书评价一般，虽然读起来确实流畅，也多少有些海猫的影子，不过，时间不太对吧。 我为什么不去直接读《竹林中》呢？我也许应该再去看看干货更多的书籍，而不是把很多哲学思想再加工的半成品推理小说？ 看完了这本书，让我有点不太想打开下一本书，也就是收获没有那么多。 好多东西堆在我眼前，可以推进我的业余项目、可以把工作精进搞好、可以去看纸牌圣经练习手法、可以学习视频制作（对了安装了fcpx，可以有时间学习视频编辑了）、可以去把之前买的狗头人桌游打开、可以尝试去运动…… 貌似又有了那种感觉，我拥有那么多东西，可是却没有办法很好的享受这些，如果我能静下心来，明明可以创造出很多很多愉快的记忆和成果的。 于此同时，我的本职工作，其实内容很简单，上传下达，文件检查，感觉还是没有把状态管理好，目前做的这些工作有点消耗精力。 静下心来，静下心来，平静的心情来感受生活是我自己目前需要做的。 原文地址","link":"/2022/04/15/arc-1-book-arena/"},{"title":"把浪漫的图灵实验变得更加浪漫-由《侦探AI》阅读想到的随笔","text":"前言有的时候有些想法会找到你，然后不断的出现～不断的出现～就好像如果是早起的梦境如果和人诉说，那么就能够记忆的更加深刻。 引子提前说明，有少量剧透～ 好久没有读早坂的作品，虽然上木系列好像通过5部完结了，不过我也没有找到资源，我在看完了一部专业书籍之后想调剂一下，因此选了这部小说。17年的作品，里面对AI的描写，很多是经不起推敲的，比如：ai如果能知道自己有框架问题，他自己怎么发现框架这个词接地呢。哈哈，经不起推敲的细节明摆着，也让我看下去了，这不就是我喜欢的作品吗？依然是我喜欢的风格，给出一个胡扯的案件，然后构建故事框架，让这个胡扯的案件变得合理，小心翼翼的透露信息，精心的构建故事，尽量让前后合理。同时又在细节上注入思考，在人物上尽量让其可爱。真是部不错的作品。所以，每天看视频也没有啥吸收和输入，我要不要再好好看看书呢？如果能让我静下来的话，看书不好吗？ 这部作品最棒的地方是给了图灵实验一个更加浪漫的解答。这给我了一个种子让我意识到了一个问题，我为什么喜欢“新本科”？我被它的什么特质吸引，以及在我眼里新本格最大的创新和意义是什么呢？我想记录的就是这样的想法。 最大的创新，以浪漫为中心获得了积极的意义虽然很多时候，我不喜欢宏观叙述，不过如果面对宏观问题，宏观的解答才是有必要的。这里的问题是：描写猎奇凶杀细节的作品到底在渲染什么，给人类有什么积极意义吗？所谓“批判性”的描写诸多分尸、虐杀等等细节真的能站住脚吗？我的答案是不能。 这里提一下我为什么不喜欢社会派的作品，因为，我认为社会派作品的内核不是推理小说。如果要反应社会问题，描写和记录他人的人生，启迪后人，不需要推理小说的载体，《红楼梦》不是社会题材吗？如果是要吸引人阅读，把推理放到装饰性位置上也无妨，但是，那就不是推理作为核心的故事了。 福尔摩斯、阿加莎克里斯蒂的作品都很棒，但是随着发展，要有创新。我的观点：新本格以浪漫化的手法，消解或者解构了凶杀元素，并在内核中歌颂了人类特有的智慧。 就消解而言，我觉得最有代表性的是《解体诸因》。猎奇杀人没有意义吗？挂羊头卖狗肉？好吧，来看看解体诸因中的处理，对于一额新本格小说，当一具尸体以奇怪的方式被分尸之时，你会感到恐惧吗？感到恶心？不是的。得益于《占星术杀人魔法》的启迪，一具尸体被分尸的时候， 我的注意力全在考虑“为什么”这么做。犹如有些人提到，有些创作是“戴着脚镣舞蹈”，推理小说的脚镣是最重的。对天谜地解的追求也好，或者对自圆其说的追求也好，总之一切诡异的目的服务于谜题，作者被舒服于付线回收，这里特别要说明的是，新本格很多时候的“失真”更加从侧面消解了凶杀的恐怖性或者负面性——放弃对现实可行性的追去带来了意料之外的效果。 （未完待续）","link":"/2020/10/08/arc-2-AI-romantic/"},{"title":"学习symfony的流水日记-0","text":"开始新的crud学习，拒绝浮躁，静心修炼，争取喜欢现在的自己。特别说明：本篇依然是流水账日记。 早起给机器添加了内存，拆了隔壁电脑的两条内存，这样我就有8g内存可以用了，很开心说不上，资源是利用起来了。开始学习symfony的crud，争取今天做点什么东西出来。symfony的安装教程 开始顺着教程走。 1php composer.phar create-project symfony/website-skeleton AccessControl 先建立个项目看看，运行之后发现检查依赖没有通过，果然还是下载symfony的二级制版本吧。检查php依赖好好把php配置好。二进制的软件去github下载了，休息休息吧。 symfony check:requirements之后产生了报告，修改时区，安装依赖， 123apt-cache search php-domapt installphp --ini 检查配置文件修复时区问题。chongqing php不认识呢,修改php的timezone，让symfony完全通过吧。 使用命令行工具建立项目。时间还是超级长，原因就是symfony使用了自己自带了composer.phar这个是没有任何的代理加持的。还是应该把整个composer全局化，并配置镜像代理。 12sudo mv composer.phar /usr/local/bin/composercomposer config -g repo.packagist composer https://packagist.phpcomposer.com 全局的代理配置好，然后重新用symfony建立项目。配置好这些之后依然exit status 128，我怀疑，其实项目已经建立好了。毕竟这个是git的报错，看着报错信息好像是我没有指定正确的用户名和邮箱，这个放一下，继续后续开发学习。建立demo项目的命令失败了。git被拒绝，看来还是要把git配置好才行。git加速教程按照这个教程配置git。希望一条命令可以解决问题。如果不行还是要调试一下git，毕竟后续还要下载好多安装包。正确的设置方式可以参考这里这里。设置好之后，github速度快很多了。如果下次碰到问题，再重新设置一次。（clash的支持很有必要）继续安装demo项目，项目自带了sqlite3数据库，这样看着就好多了。重新安装php对sqlite3的支持库，然后继续更新。突发奇想，要不我就不用mysql了？目前没有看到sqlite3有什么不好，如果并发数不是那么多的话，如果没有事务要求的话……先看看吧，再犹豫一下比较好。status 中128的错误还是在报错，简单设置一下吧。 12git config --global user.email &quot;test@mail.com&quot;git config --global user.name &quot;MyName&quot; 设置好之后以后再报错就再说。刚刚就是上午的工作了，进行了午餐，之后继续下午的工作。一抬手就发现根本无法使用demo项目，并不了解程序的运行逻辑和入口。这个就放一边，先把入门的hello world写好再说。路由模块找不到对应的方法，也就是说，我的apache应该没有配置好或者模块哪里有问题。自带的symfony服务器工具非常好用和方便。 我发现一个问题，利用apache的子目录来进行测试，是因为我太喜欢80端口了。这个习惯不好。另外，symfony本身这个命令建立的网站就是独立网站了，最好能有一个独立虚拟目录给他，这样才是便于测试和理解的。 继续调整了配置后发现，在这个框架下，public才是网站应该指向的地址，这样逻辑就顺了，symfony new project_name 中的name原来是最顶级的名字，把他理解为自模块应该是我在mvc.net中学到的不好的习惯。 虽然现在访问起来依然是index.php/lucky/number。不过网站是可以访问了。根据开发建议使用symfony自带的服务器这一点，我觉得还是忽视这个问题比较好。解决问题的教程在这里 完成了create pages的教学，下一步看from模块，争取一个模块一个模块的看过去，完成symfony的学习和使用。 form模块就很复杂了，休息了一下，把form模块的代码实践完。label写好了，中文也能改，这不就是把我昨天做二维码界面的工作重构了吗？感觉还是挺好的。虽然，我记忆中，mvc耦合文件图片等等事情的时候，我还是没有怎么搞懂……至少是没有找到最佳实践。 看完了form模块，从数据库和模板里面我选择模板，哈哈，虽然每个都很麻烦，但是，数据库可以再等等嘛~……等等，我刚刚应该是调用task_success失败了，虽然解决了也大致知道怎么回事儿了。还是按照文档的顺序来看吧（打下这句话的时候，我已经看完了）。","link":"/2020/07/02/arc-3-symfony-0/"},{"title":"学习symfony的流水日记-1","text":"昨日和宇视科技的技术人员了解硬件信息因此断更，今天继续我的symfony流水账学习。昨天突然想到我的应用可能一开始就要处理1对多关系，想想有点头疼呀。 早起集中精力先看controler文档。看文档发现的心得，虽然我在用php，但是当我因为一个文本没有编辑好，结果整个项目无法访问时，当我看到type hint给contrler传入一个接口，结果这个接口直接可以用时（肯定用了依赖注入把）。我就想，我是不是只是用php语法去实现了某个东西，好多都是静态语言的特性。只是因为用了php就想php扮演的多大的角色（当然，php也很重要），肯定是不合适的。 流水笔记有个好处，就是当我想向别人输出的时候，重定向到这里，感觉能轻松很多，也有所收获和积累。 中国企业的求生欲，藏在微信里 有点累，读一下水文，放松放松。放松好了，集中宝贵的经历，看教程，毕竟，后续还想安排通读DEMO教程呢。 模板看完了。继续看配置模块。配置看完了，要看数据库访问了。 午餐时间，吃了点东西，然后继续配置我的开发环境，把最近的文档整理一下，另外，看看能不能给机器搞个双显卡。^_^，日常折腾呢。 服务器资源访问不到。这个感觉问题更大一点，虽然目前还不是太重要就是了。 中午折腾机器，发现安装独立显卡后，集成显卡没有输出了。这是硬件特性吗？暂时不管了，继续看数据库访问吧。今天周五，周六放假等着我呢。数据库也看完了。这样最基本常用的模块我就都看过了。虽然部署，配置等等也有很多模糊和需要学习的地方，bundle也没有看，ajax也没有看到，用户验证部分也没有看到……哈哈，总之，我先把demo模块读一次吧。 这次是读代码了，仔细想想，我没怎么好好看过代码，经常是自己摸索出奇奇怪怪的套路，这次好好看一下是个不错的机会。 ……打开代码，vs提示要我配置git和php……又开始折腾了，我是真的喜欢折腾静不下心来啊。看了一小下demo的代码，感觉……没有太大感觉，还是自己上手至少先把qr编辑器做好吧。 启动apache2，开始建立我的qr配置部分，然后慢慢的就把各个部分都做好。php bin/console make:controller qrConfigController生成控制器。 引入bootstrap部分我就迷茫了……哈哈，没有那么简单的事情呢。{{ encore_entry_link_tags('app') }}这个总是报错。 原来我终于到了需要先把css编译才能使用的这一步。安装yarn还安装错了。哈哈。Google一下我发现我遇到的是wsl的bug……暂时放弃webpack把，这个功能感觉过于先进了。curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -这个命令出错了。 下班回到家然后，工作上感觉还是在推进一下比较好，因为稍稍有点危机感。打开电脑，配置好代理，命令敲完，发现借助现代的工具配置项目果然还是简单呢。 123export https_proxy=http://127.0.0.1:6152;export http_proxy=http://127.0.0.1:6152;export all_proxy=socks5://127.0.0.1:6153 代理帮了大忙了。 建立一个新项目吧。crud还是要学习一下的。brew services start mysqlHomebrew 都能管理服务了……真是变化大啊放个9年前的帖子，不知道还能不能用，至少mysql -uroot可以直接访问数据库是真的。 可以用，直接建立好数据库了。php总是调用3.7版本，是环境变量的问题原来是zsh的问题……真是各种坑等着你啊。……仔细思考了一下，并不是这样的！！环境变量的顺序没有错，/usr/local/bin确实是在最前面，问题可能是我刚刚才安装php到local，而没用重启，我怀疑zsh缓存了每个环境变量下的目录，所以找不到我的PHP。重启一下terminal看看； 果然啊！！居然是和上一次一样的错误。就是安装php扩展后，命令行可以正确执行gd图像生成，可是apache2不行。","link":"/2020/07/04/arc-4-symfony-1/"},{"title":"科研文献审稿经验心得分享","text":"初衷在实验室学习的过程中，经常能从导师那里接到一些审稿文章，而后进行一些审稿工作。开始几次审稿的时候我自己都还没有发过文章，文献读的也少，因此，吃力程度可想而之。借助google在网上固然可以得到很多相关的资料，其中很多帮助很大，但是大部分资料都是审稿回复的一些基本语句，还有就是，学术大牛对在投文章如何看待审稿意见的建议。 我一直以为对于任何事物的学习过程而言，开始的时候总是有其特殊的困难，因此对于开始一项学习而言，需要最入门简单的教程。而对于审稿工作，每个研究生第一次接触的时候总会有这样那样的困惑或者是更一般的无从下手的迷茫。笔者自己面对新工作的时候经常会不知道干什么而拖到Deadline的最后一刻，利用Deadline生产力原则来完成工作，不过我知道，这当然是不好的，事物的学习还是遵从它自然的规则更好。因此，写这篇随笔来记录一下自己的审稿心得，一方面是对自己学习的总结，另一方面希望对初次进行审稿的研究生同学提供一点点帮助。 审稿的基本概念考虑到这是一篇基础性文章，请允许我不厌其烦的介绍审稿的诸多细节，虽然对于很多人特别是经历过科技文章写作投稿的人来说，这些都是无意义的堆砌，但是，我回忆自己学习经历的初期，确实对“审稿”，“期刊”，“编辑”这些基本概念也是要一点点的查过来的，因此我想对于初学者，这种基本的介绍还是有帮助的。 首先是出版社（比如 Elsevier, Wiley等都是著名的科技文献出版社），出版社是一个商业组织，出版社旗下有很多的期刊，这些期刊上面刊登着世界各地的研究者以科技论文的形式发表的自己的研究成果。不同的期刊关注科学研究的不同领域，而出版社负责组织这些期刊。可想而知，科学研究的内容是一般是复杂的，而且针对具体的领域又很有深度，管理好一个期刊使期刊可以真正促进对应的学科进步是一件困难的事情。另一方面，出版社也非常关心的一件事情是如何保证自己期刊文章的质量。而审稿制度就可以在一定程度上解决这个问题。 简单说明一下文章发表的流程，从文章产生的角度，首先最开始当然是研究者选择课题，进行研究，并将研究成果以科技论文的形式撰写出来并投稿到自己想要发表的期刊。然后期刊的编辑会接收到文章，编辑的工作就是初步检查文章的内容并确定这篇文章是否符合期刊的发表要求。由于文章多涉及专业的研究内容，因此，编辑在确定文章的研究课题大致符合期刊要求之后，需要进一步对研究质量进行检查。编辑会在这个文章对应的研究领域里选择若干名专家，将文章发送给这些专家，由专家对文章的研究价值、创新性、研究严谨性进行评审，并给出审稿意见，这些审稿意见会返回给编辑和作者，一方面帮助编辑判断该文章是否适合发表，另一方面帮助作者完善其研究。当一篇稿件送到研究者手中时就形成了审稿的工作。 审稿的意义说明了审稿的作用之后，来考虑一个问题，我们为什么要审稿呢？ 虽然这个问题看似高大上，有点近乎哲学的意味了。不过，其实还是很简单的问题。讨论为什么要审稿之前，我们来说一下“学术共同体”。这是一个稍微抽象的概念，大致上可以理解为所有从事科研工作的人员的集合。科学研究是一个漫长艰辛的过程，时间长，工程庞大，内容繁杂，稂莠不齐，同时还经常会反复，因此，科研工作非单一个人、组织、甚至是国家可以完成的。所以，科学研究者们互相帮助，有时获取资源，有时提供帮助，在长期的运行过程中，慢慢形成了一个有利于科学研究进步的组织结构和行为规则这就是学术共同体了。 对学术共同体有了了解之后，其实很多科研中遇到的概念都可以很好理解了。比如，为什么学术造假时非常恶劣的行为？那是因为造假的研究结果会在学术共同体内传播，影响很多人的研究，甚至将一个学科引向错误的方向毁掉一个学科。为什么研究成果一定要以发表论文的形式来表现？那是科学研究的成果只有发表出来，才能使学术共同体内的其他人了解到你的研究，从而帮助整个学术共同体推进研究的进程。 解释完上面的内容，审稿工作的意义也就很好理解了。从学术共同体的角度来说，审稿工作是每个科研工作者的义务。就像Google Scholar首页上那句话一样“Stand on the shoulders of giants”，可以很容易的想见，如果没有大量优质的文献支撑，一个研究者很难了解自己到研究领域的研究历史、研究重点，没有对当前的研究进展的了解作为基础的话，创新的研究成果就无从谈起了。因此，每个研究者需要利用自己所具有的对自己研究专业的知识、经验帮助其他科研工作者完善他们的研究工作，或者提出批评、或者提出建议。同时帮助编辑判断研究工作的价值，一定程度上防止有问题的文章发表出来。 是不是很有责任感？其实，对于审稿人而言，审阅他人的文章也是自己学习进步的过程。不同观点看待一个事物的过程中很容易产生创新的想法。 需要完成的工作既然本文想着重介绍的是入门，那么就来说说针对一篇审稿我们要做什么。 首先，拿到一篇审稿的第一步，了解审稿的期刊来源，期刊研究的是什么内容。同时了解文章作者的背景信息，包括这个作者的研究领域，所在的单位，之前的研究成果。这些都是帮助我们理解文章的基本内容。针对入门的同学，再补充一个更为基础的问题，哪里去找这些内容呢？如果是中文审稿的话用作者的名字一搜也许就找到了，如果是英文呢？其实道理是一样的，查找信息的方式就是把英文当成你的母语设置关键词去检索你需要的信息。很多研究生同学（包括我自己）都是开始的时候对英文很头疼，不过和其他所有的学习过程一样，只要坚持其实很快就能适应。这里说明一下了解任何一个作者的捷径，就是看作者发表的文章，这个相当于第一手资料，快速的浏览作者的文章的题目、摘要、图片你就可以了解作者。很多时候拿到的审稿和我们自己的课题稍微有点远，因此我自己的经验是先通过作者之前的研究了解基本背景，这样读的时候，更方便发现文章的研究重点而防止自己的精力被不重要的细节分散。 然后，仔细阅读文章全文。所谓仔细阅读全文的方法因人而异，有些人会逐段读，而我自己因为经常被人打断思路，而且我读英文比较慢，因此我会先和看一般文献一样快速通读，了解文章到骨架，然后细致阅读补充内容。审稿阅读的和一般阅读是不同的，因为你是有目的，所以需要“带着问题读”。这篇文章的研究背景是什么？创新点是什么？当前研究的瓶颈或者关注的焦点是什么？解决什么问题？使用了什么方法？作者得出了什么结论？作者如何用他的实验支撑结论？作者使用的方法是否可行？作者的数据是否可信？带着这些问题会帮助你更好理解文章，这中间也需要阅读相关的文章。 最后，阅读完之后就是要给出审稿意见，指出作者需要修改的错误，提出需要完善的地方，帮助作者改进他的文章。另一方面对于不合格的文章需要给出拒稿意见，要指出作者的问题。 对文章进行评价对于一篇文章，需要给出处理建议，一半包括小修(Minor revision)、大修(Major revision)、拒稿(Reject)，根据什么标准来判断给出处理建议呢？ 对于一篇科技论文来说，文章的基础应该是科学的严谨性，严谨性在于理论多选取、方法的可行性、甚至是数据的可信性。另一方面，学术论文的价值在于创新，文章的核心工作不应该是重复性的，应该是全新的，同时创新性来源于对前人研究的总结改进不能是凭空产生的，对于一篇合格的文章，引言部分需要核心论证的就是文章的创新性，因此，不合格的文章大致是以下三种情况： 1. 没有创新性； 2. 数据不可信； 3. 研究工作没有意义。 如何发现和说明这些问题呢？这就需要审稿人阅读相关领域的文献，动笔计算文章中的数据，认真的分析文章研究结论的合理性。我个人经验是阅读文章的过程中，一定要形成自己的观点，一旦你有了自己的观点和认识，你就不会被作者牵走。更重要的是，你的观点和作者不同的时候，你就就会有自己的问题，这些问题会帮助你分析和这个审稿相关的文献，加深你对作者研究内容的理解，最终使你可以更加客观评价审稿文献。 结尾以上就是我个人对于审稿工作的经验分享，希望对后来人有帮助。","link":"/2015/12/08/arc-5-science-paper-review/"},{"title":"阅读与js相关的书籍","text":"更新尽量不要停如果没有什么内容，我更新一下读书笔记吧，就是这两本。 js的可靠代码，最终内容还是设计模式。这样也是非常有道理的，可靠就是解除耦合，解除耦合就是合理的设计模式，这本书自然而然的讲了如何用js实现各种设计模式。让我惊艳的地方有两点： 全书围绕着一个例子展开讲，把一个大会支持网站的例子的每一个部分都渐进式的讲到了； 全书都在坚持采用“测试驱动开发”的模式，讲解了如何测试各类设计模式； 内容方面，丰富的设计模式，让我反思之前没有好好学习应用设计模式是不是一种小损失。另一本，全家桶就看的比较快速了，毕竟更新的内容太多了。官方甚至都在主教程里推荐next.js了，肯定很多内容不相符。不过，我还是认真阅读了redux相关的内容，尝试去理解这个库的设计与使用。 其他随笔把旧blog迁移过来的事情还没有进度，放松的的时候一篇一篇来吧。","link":"/2023/05/10/book-0-read-about-js/"},{"title":"《折断的龙骨》读书笔记","text":"前言一个相对清闲了下午，约了友人晚上吃饭，友人下班略微晚，有个小间隙，又开了一本书。契机也是非常神奇，晚上看up主解说《向日葵不开的夏天》的时候，他说明设定系作品的时候同时举例子《死了七次的男人》和《折断的龙骨》。然后，让我想到了，如果看下一本的话，就看看龙骨吧。 这次如果有什么不同的的话，就是我要好好的记录读书笔记，你看到的这篇文章就是我在开读的时候记录下来的。 序章我非常喜欢这个序章！仿佛找到了古早的感觉，简洁的介绍了人物和框架，并且奠定了基调。如果有什么感触的话，那就是看到了当初我看《金田一一事件薄》的感觉，我最喜欢的那句开头。“河边一具尸体，无论如何也查不出身份，当时我们不可能知道，就是在这里开始了悲剧的序幕”。 开篇小插曲 第一个笑点出现了，这个名字，如果说这是中国人，那就是“巴嘎推理”展开了。 我特别想吐槽你，这名字奇怪吗？那个法克儿才奇怪吧！！文档到这里应该没有剧透，后续，我就尽量不放原文了。 “法尔克在一瞬间就认定了我的身份。这样的人我还是第一次见。刚刚他提到逻辑，莫非是亚里士多德的信徒？”莫名其妙的与我在看的另一本书联动了。 沉浸阅读直到结束看完了。对，从刚刚那行字到现在，我发烧了三天，然后恢复了两天。是的，在发烧的过程中，我断断续续的看完了折断的龙骨。大概率的原因是因为和友人吃饭的时候吹了凉风，风寒发烧。 和《死7》感觉一样流畅，感觉是非常好的作品了。如果说逻辑的体现也非常正统，在临近书结尾的部分，登场人物慷慨陈词，完成剧情的高潮，并把所有的伏线都收回来。嗯，推理小说实至名归。 当时看《死7》的时候半夜不睡觉偷着看。相比于《死7》，这本书的阅读是不是能算更健康一点呢？不好说。至少很长一段时间内，我不准备因为任何不必要的事情牺牲睡眠了，发烧生病，让我觉得应该好好保重身体。 涉及剧透的一些笔记其中有个魔法师，是穆斯林，作者用语言误会（《两个人的距离概算》里有类似的手法）和宗教习惯构建的解答，其中让我特别惊喜的是，阿拉伯人是使用的魔法是希腊的巨人。这似乎正是映射了某些历史事实，文艺复兴的源头，阿拉伯的贡献等等，都被浓缩在小小的细节设定里，非常有意思。 尾声个人其实并不太喜欢这部作品，看完之后，我又想起了《连峰之间是否放晴》，还是更加喜欢这类能引起我共鸣的作品。","link":"/2023/11/17/book-1-the-broken-dragon-bone/"},{"title":"《数理逻辑--证明及其限度》读书笔记","text":"前言我要读《数理逻辑–证明及其限度》。写下这篇文章的时候我还在看龙骨，想不到我自己可以同时开两本书的阅读。契机就是看到了lean语言，读到了一些科普读物。尝试要在图书馆借一本书，不过，最终借到的教材不太好，最终选择了买二手书。 我希望这本书也能读完，因为我考虑形式证明如果能用lean这样的语言实现，那么是不是可以再区块链这类协议中应用呢？AI应用即然不准确，是不是把逻辑模块添加进去能加强整体性能呢？现在各种AI编辑软件其实都不好用，解决不了问题，我是否能做出来一个特定领域解决极致的问题呢？等等、等等想法，希望我在读完这本书后能获得一部分解答，或者获得更多的问题。 进度缓慢备忘参考资料Lean 4 定理证明让我心心念非常感兴趣的编程语言。","link":"/2023/11/17/book-2-mathematical-logic/"},{"title":"《Proxmox VE 超融合集群实践真传》读书笔记","text":"前言利用工作的间隙（也可以说是工作需要），读了这本书。先说结论：是一本非常棒的书。市面上关于pve的中文书籍并不多，这位作者能把书写完并出版真的是非常不易。 如果是过去的我，可能并不会喜欢这个书的风格，因为“深度”不够，比如：作者拿出来一个小节讲解虚拟机的创建，销毁，这些基础操作过于简单而浪费篇幅了，相对应的“深刻”的技术原理和规律却并不多。不过，这次的阅读中，我却感觉意外顺畅，变化最多的应该是我的心态。因为我能明显感觉到作者实战经验丰富，他愿意把自己的经验整理分享出来，我通过静静地阅读就能获得这些知识，真的是非常棒的。 生活中，我发现我个人缺少的表达和倾听的能力，我如果能够静静地慢慢地做我喜欢的和擅长的事情，大概率是能做好，一定概率可以做的非常之好，静静地看书能让我在长跑路上不断进步，像我父亲说的：“更高更快更强”。静静读完这本书，然后挑战数理逻辑的学些，我觉得未来肯定会感谢现在的刻苦用功。 一些阅读感受非常喜欢第七章的例子，只有一台机器，合理利用达到了非常好的效果，并且对关键的HAPROXY给出了详细配置。特别棒的阅读体验是，在文章的最后，用列表的方式给出实际效果的时候，居然不经意间透露了这个创业公司的项目：自动售货机。感觉是非常新奇的体验阅读体验，仿佛“推理小说”一把，在最后告诉你，这些“IT系统”实际在应用中支持了什么样的工作。 作者在行文中还会明显记录一下当时他的想法，甚至是弯路。我突然看到了非常熟悉的感觉，这不就是我自己写的文档吗？也就是说，因为我自己的开始不断输出了，所以，我再吸收的时候读的更加顺畅了！！！果然，坚持做正确的事情就是有回报。这也更加坚定了让我多写、多输出（无论是公开的输出，还是私下的写作笔记），让自己获得正反馈。 下单新书看完了PVE果然开卷有益，让我了解了一片新的天地，趁热打铁，我又下单了关于KVM的书籍。同时利用手边的电脑快速开启各种实验，先体验体验OpenMediaVault的功能。","link":"/2023/11/30/book-3-proxmox-VE/"},{"title":"《虚拟化KVM极速入门》","text":"封面 前言虽然琐碎的工作很多，但是，还是要加强学习保持充电为未来做准备。依然是非常朴实的书，就是讲解日常操作，顺利读完可以补充非常多的基础知识。想到很多时候，不管是运维还是开发，更多的是有条理的组织起基础工作，从这个角度考虑读这本书挺好的。 笔记QUME这个东西，10年前就听到同学介绍过，当时如果好好学，直接就在linux体系里学习是不是会有很好的收获呢？也不一定。libvirt，virtIO、virt-manager等这些关键词也真实的的了解到了，并且特别好的一点，书里用cockpit做例子，非常实用。 读书真的是学习的捷径，只要能静下心来好好读好书，其实就可以节省非常多自己试错的成本。今天有个好消息，用于支持虚拟机学习的内存到货了，希望内存安装可以顺利。 实验环境开始开始了新的学习，首先是文具的就位。 借助教程和网友建议，准备开启windows的虚拟化选项，给自己建立一个简单的实验环境。 实际处理的时候：关闭所有的hyper-V服务项目、取消所有的虚拟机功能、关闭windows本身的内核保护，这样就可以嵌套虚拟机开始学习了。 操作记录默认安装的服务器版本，没有gui，即使是软件包中也没有包含gui的选项，思考了一下，也许可以尝试不用GUI，就用fedora39锻炼一下也未尝不可。第一个问题，先执行一下dnf update。发现速度很慢……果然第一项还是设置更新源吗？实际运行发现安装软件包非常快速！然后解决联网的问题，我突然灵光一动，保证外部可以访问，也保证可以联网，只要配置两块网卡就可以了，这样还能熟悉一下网络配置。 一步一步完善cockpit的使用，首先是安装文件管理器，这样上传下载文件能方便许多，文件管理器。 sudo dnf install cockpit-navigator这样就能进行文件管理了，利用文件管理可以上传ISO镜像，这样就可以安装操作系统了。 一开始就碰到了权限问题，NFS默认是无法写入，只读的。查了一些资料，no_root_squash等适当的配置选项可以解决问题，不过这样感觉不安全，后来看来的教程提到可以将文件夹other属性打开，这个思路更加合适。虽然可以用终端解决，但是想了一下，还是尽量学习一下OMV吧。 把权限设置正确之后就可以使用NFS了。 快速开始第二本书东凑点时间，西凑点时间，虽然断断续续，但是最终还是把第一本入门看完了，开始了第二本的阅读。 这次阅读之所以这么快也是因为实操实验进行的少。收获也是非常大的，入门教程里把虚拟机的虚拟网络解释的非常详细。 这本书更多的是利用间隙去看，其中很多内容，corosync、pacemaker等这些高阶项目确实让人受益匪浅，了解了非常多之前不知道的知识，比如stonith设备。比如集群的高可用本质就是让虚拟机在物理机器上飘移，再比如，virsh居然有如此的配置参数，而配置方式就是简单的XML文件，再比如，NUMA的vcpu和cpu的位置居然是可以指定的，等等。实体书可以留下来，这样后续如果有用到相关的内容可以快速参考。 小结kvm这本书真的是开卷有益的典型，如果早点知道这些内容，也许我就会更早采用kvm技术栈。可惜，一开始准备的内存其实并没有发挥什么作用。 操作笔记尝试安装了ubuntu，然后意识到了ubuntu默认的磁盘管理已经到了lvm了，刚好学习一下。这里是操作参考","link":"/2023/12/05/book-4-KVM-start/"},{"title":"写给自己的博客使用笔记","text":"博客管理本博客为个人博客，联系方式见首页。 本文章记录一下博客的管理使用说明，防止每次都忘记。 添加文章1npx hexo new &quot;about ts type not in runtime&quot; # please run this command in project Folder 执行以上命令可以添加文章，然后就可以撰写文章了。 生成并发布网站1npx hexo g -d 执行该命令可以直接生成并重新发布网站。（提醒一下，记得关注网络状态）。 修改文章之后本地预览网站12npx hexo g #生成网站npx hexo s #生成预览服务器 官方教程如下Create a new post1hexo new &quot;My New Post&quot; More info: Writing Run server1hexo server More info: Server Generate static files1hexo generate More info: Generating Deploy to remote sites2023-11-9更新：使用了github的workflow自动部署了，这样就不用这样的方式了，git提交之后，就可以自动更新。 1hexo deploy More info: Deployment","link":"/2020/04/24/hello-world/"},{"title":"心境转变了一次记录","text":"心境变化的起因虽然很多时候，有“差生文具多”的嫌疑，我自己的google blog其实也没有太多问题（只是访问不了而已）。不过还是花了不到一个小时的时间把这个博客架设起来了～ 起因非常突然，今天突然看到了我的github绿色马赛克多了（如上图），我意识到自己最近一段时间状态不错😌。想着把博客也转过来吧，把笔记本里沉睡的一些东西写出来。虽然有点担心自己写的东西不成熟，也许日后看来是胡言乱语，但是想着还是公开出来比较好。未来可以整理吗～～ 我沉迷typescript了最近，开始痴迷了typescript和对对应的前端开发，react,next.js,vscode，github，等等很多东西让我有点静下心来了。有点点收获，比如，发现在ts中，reduce真的可以完全代替循环存在，于是乎，写出了以下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142const FitInfo = (carList: CarItem[]) =&gt; { const combine = (years: string[]): string =&gt; { const year_combine = years.reduce((acc, year) =&gt; { if (acc === '') return year const left = acc.slice(0, acc.lastIndexOf(',') + 1 + 4) const right = acc .slice(acc.lastIndexOf(',') + 1, acc.length) .slice(-4) if (Number(year) - Number(right) === 1) return left + '-' + year if (Number(year) - Number(right) &gt; 1) return acc + ',' + year return acc }, '') return year_combine } const description = sort(carList) .asc([(u) =&gt; u.make_name, (u) =&gt; u.model_name, (u) =&gt; u.year_name]) .map((v) =&gt; { return { carname: v.make_name + ' ' + v.model_name, year: v.year_name, } }) .reduce((acc, item) =&gt; { if ( !acc.some((it): boolean =&gt; { return it.carname === item.carname }) ) { acc.push({ carname: item.carname, year: [item.year] }) } else { const obj = acc.find((it) =&gt; it.carname === item.carname) obj?.year.push(item.year) } return acc }, [] as { carname: string; year: string[] }[]) .reduce((acc, item) =&gt; { return acc === '' ? item.carname + ' ' + combine(item.year) : acc + ';' + item.carname + ' ' + combine(item.year) }, '') return description} 我自己突然有些联想，长辈提过他上学的时候就是学习的lisp，不知道能否和他交流（大概率是不行吧🙍‍♂️）。lisp把数据和程序混在一起。我再看这段代码，循环完全是用reduce实现的，也许真的存在严禁证明for可以是不必要的。map、reduce就可以完成遍历操作。在我的程序中，为了实现目标，我引入了很多中间神奇的数据结构（指的是{ carname: string; year: string[] }），也许这就是数据和程序混在一起的感觉？利用数据结构来实现循环目标？不清楚了，希望我也能有朝一日接触到学院派的内容。当然，希望接触目标的时候能有足够的实践：比如，写个智能合约😊。 大概就是这么多，有点点困了，指针过了12点了，晚安。","link":"/2022/09/23/inner-peace/"},{"title":"某天在咖啡厅","text":"在一个咖啡厅重启了博客感觉每次写下博客总是在“重启”……都是更换平台，或者间隔好久，希望能把这次更换平台算到最后一次。 AI学习开始了一年前，我在kaggle上学习课程，同样是一年前，我开始学习react，如果回顾一下过去，我发现自己依然是“乱冲乱撞”。不过，确实收获了很多内容，这些学到的东西也许哪天能发挥作用。比如，了解了ts，发现了几乎是我梦寐以求的编程语言，顺路也了解了函数式编程。 另一个好消息是，2023年年初，AI应用爆发了，也许是个新的机会，如果我能抓住或者至少能利用起来就好了。依然希望我的未来能有更好的故事。 家里的好消息Rain考上大学了，真的是非常好的消息，全家人都开心。终于体会到那种我还把她当小姑娘但是其实已经是大孩子的感觉了。再有4年，小Rain也毕业了，那会儿会怎么样呢？3月的最后一天知道这个消息的，就把这天当作纪念日吧。 生活中充满了小惊喜生活中的小惊喜总是不断出现，比如，去买个蛋糕碰到了过家家的联名。 虽然，有时下雨不过总有开心的事情，对了，在妻子的帮助和鼓励下，我开始准备发展一些副业，也许这是新的难以想象的神奇经历的的开始。 学校的面条意外的好吃，吃了好多天，我还开玩笑的封这个面条为“天下第一面”，想起来去年的时候，想吃都吃不到。如果要说什么是小确幸的话，这个面条当之无愧吧。 找到了好玩的游戏买了《密特罗德究极重制版》，真的想把这种感觉记录下来。 游戏中的氛围非常有沉浸感，不断的升级、跑路、探索，果然是经典，能相遇太好了。目前游戏还没通关，准备单开一篇聊聊感受。","link":"/2023/04/02/some-day-in-the-coffee-shop/"},{"title":"start my AI side project with cf","text":"准备开始我的AI项目了读了两本书，感觉找回了当初“开卷有益”的感觉。从图书馆借书其实非常的方便，这让我想起了大学的时候，那会儿就是每天每天不停的看书。很多学到的东西收益终身。 现在要开始新的征程了，东撞西碰的回顾这么多年，发现github是个非常好的网站，即使几度放弃，结果，最终发现，最可控也最方便记录的居然是这个小小的静态博客。不知道有没有精力能把google.blog上的文章搬过来，也许这个目录未来会很大，不过，也许我也写不了那么多内容吧，谁知道呢。借助cloudflare的cdn和pages换了一个独立域名,发现意外的顺畅……再次感叹如果有好的IT基础生态，喜欢“折腾geek”得是每天都生活在幸福中吧。 在经过多次尝试和思考后，最后想着，要不先选择cloudflare这个平台（腾讯云上已经开通的虚拟机还是准备维持着），尝试开始新的项目，担忧也不是没有，只是希望这次能是个有反馈的长赛道。 后续的文章还是编号吧，这样便于管理，看了书，下一步就是熟悉各类项目了，先从记事本开始也许是个不错的主意。","link":"/2023/04/12/start-my-AI-side-project-with-cf/"}],"tags":[{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"教程","slug":"教程","link":"/tags/%E6%95%99%E7%A8%8B/"},{"name":"读书,折腾","slug":"读书-折腾","link":"/tags/%E8%AF%BB%E4%B9%A6-%E6%8A%98%E8%85%BE/"},{"name":"旧博客","slug":"旧博客","link":"/tags/%E6%97%A7%E5%8D%9A%E5%AE%A2/"},{"name":"读书","slug":"读书","link":"/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"说明","slug":"说明","link":"/tags/%E8%AF%B4%E6%98%8E/"}],"categories":[],"pages":[]}